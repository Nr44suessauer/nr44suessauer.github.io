{"_path":"/articles/ollama-intruduction","_dir":"articles","_draft":false,"_partial":false,"_locale":"","title":"Ollama Intruduction","description":"How To run AI Models on your own PC | Beginner Guide","cover":"https://imgs.search.brave.com/8xshJuTEcdDh4ATRrUMvxIB39O6v3yf7382wqSkPcWg/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9jZG4u/YnJhbmRmZXRjaC5p/by9pZHJSRG1aMl9G/L3cvMTgwL2gvMTgw/L3RoZW1lL2xpZ2h0/L2xvZ28ucG5nP2M9/MWJ4aWQ2NE11cDdh/Y3pld1NBWU1YJnQ9/MTc0Nzc0NDA3MTE3/OA","date":"2024-07-28T00:00:00.000Z","layout":"article_backup","order":2,"body":{"type":"root","children":[{"type":"element","tag":"style","props":{},"children":[{"type":"text","value":"\n.ollama-navbar {\n    display: flex;\n    gap: 16px;\n    margin-bottom: 24px;\n}\n.ollama-navbar-btn {\n    background: #007bff;\n    color: white;\n    border: none;\n    border-radius: 6px 6px 0 0;\n    padding: 12px 32px;\n    font-size: 1em;\n    font-weight: bold;\n    cursor: pointer;\n    transition: background 0.2s;\n    outline: none;\n}\n.ollama-navbar-btn.active,\n.ollama-navbar-btn:hover {\n    background: #0056b3;\n}\n.ollama-navbar-content {\n    background: #000000ff;\n    border-radius: 0 0 8px 8px;\n    box-shadow: 0 2px 4px rgba(0,0,0,0.08);\n    padding: 24px;\n    margin-top: -2px;\n    border-top: 1px solid #ddd;\n}\n"}]},{"type":"element","tag":"div","props":{"className":["ollama-navbar-tabs"]},"children":[{"type":"element","tag":"input","props":{"type":"radio","name":"ollama-tab","id":"ollama-tab-0","className":["ollama-tab-radio"],"checked":true},"children":[]},{"type":"element","tag":"input","props":{"type":"radio","name":"ollama-tab","id":"ollama-tab-1","className":["ollama-tab-radio"]},"children":[]},{"type":"element","tag":"input","props":{"type":"radio","name":"ollama-tab","id":"ollama-tab-2","className":["ollama-tab-radio"]},"children":[]},{"type":"element","tag":"input","props":{"type":"radio","name":"ollama-tab","id":"ollama-tab-3","className":["ollama-tab-radio"]},"children":[]},{"type":"element","tag":"div","props":{"className":["ollama-navbar"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"label","props":{"className":["ollama-navbar-btn"],"htmlFor":["ollama-tab-0"]},"children":[{"type":"text","value":"üìã Preparation"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"label","props":{"className":["ollama-navbar-btn"],"htmlFor":["ollama-tab-1"]},"children":[{"type":"text","value":"‚öôÔ∏è Setup"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"label","props":{"className":["ollama-navbar-btn"],"htmlFor":["ollama-tab-2"]},"children":[{"type":"text","value":"üéÆ Model Playground"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"label","props":{"className":["ollama-navbar-btn"],"htmlFor":["ollama-tab-3"]},"children":[{"type":"text","value":"üîß Troubleshooting"}]}]},{"type":"element","tag":"div","props":{"className":["ollama-navbar-content","ollama-content-0"]},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"div","props":{"style":"margin-top: 24px; margin-bottom: 24px;"},"children":[{"type":"text","value":"\n            "},{"type":"element","tag":"h4","props":{"id":"before-you-begin"},"children":[{"type":"text","value":"Before You Begin"}]},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"If you are opening this guide, you have probably heard a lot about artificial intelligence and now want to get your hands on it yourself. But perhaps you also feel a little overwhelmed by terms like \"local LLMs,\" \"Jupyter Notebooks,\" and \"Virtual Environments.\" Don't worry, that is completely normal! This tutorial was written specifically for absolute beginners like you."}]},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Our goal is to show you how to run powerful AI models directly on your own computer. This is not only incredibly fascinating, but it also offers you full control over your data, maximum privacy, and the freedom to use AI models without an internet connection or expensive cloud services."}]},{"type":"text","value":"\n        "}]},{"type":"text","value":"\n    "},{"type":"element","tag":"table","props":{},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"tbody","props":{},"children":[{"type":"element","tag":"tr","props":{},"children":[{"type":"text","value":"\n            "},{"type":"element","tag":"td","props":{"align":"center","style":"width: 180px;"},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"img","props":{"src":"https://imgs.search.brave.com/V2oVVCsPaNxkGlhMMz5AxhgzgEvkZRmyQf3x22R5ebQ/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9hc3Nl/dHMuc3RpY2twbmcu/Y29tL2ltYWdlcy82/MmE3OTA2Y2U0MmQ3/MjlkOTI4YjE3NTcu/cG5n","alt":"VS Code Logo","style":"max-width: 100px; max-height: 80px; display: block; margin: 0 auto;"},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"a","props":{"href":"https://code.visualstudio.com/download","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"VS Code"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"td","props":{"align":"center","style":"width: 180px;"},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"img","props":{"src":"https://www.python.org/static/community_logos/python-logo.png","alt":"Python Logo","style":"max-width: 100px; max-height: 80px; display: block; margin: 0 auto;"},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"a","props":{"href":"https://www.python.org/downloads/","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"Python"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"td","props":{"align":"center","style":"width: 180px;"},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"img","props":{"src":"https://imgs.search.brave.com/8xshJuTEcdDh4ATRrUMvxIB39O6v3yf7382wqSkPcWg/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9jZG4u/YnJhbmRmZXRjaC5p/by9pZHJSRG1aMl9G/L3cvMTgwL2gvMTgw/L3RoZW1lL2xpZ2h0/L2xvZ28ucG5nP2M9/MWJ4aWQ2NE11cDdh/Y3pld1NBWU1YJnQ9/MTc0Nzc0NDA3MTE3/OA","alt":"Ollama Logo","style":"max-width: 100px; max-height: 80px; display: block; margin: 0 auto;"},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"a","props":{"href":"https://ollama.com/download","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"Ollama"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"td","props":{"align":"center","style":"width: 180px;"},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"img","props":{"src":"https://imgs.search.brave.com/zLvtdX6w_dNUl6wAzFN-0BCdZQrJu7VkSySkbESjtsc/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly91cGxv/YWQud2lraW1lZGlh/Lm9yZy93aWtpcGVk/aWEvY29tbW9ucy9i/L2I5L052aWRpYV9D/VURBX0xvZ28uanBn","alt":"CUDA Logo","style":"max-width: 100px; max-height: 80px; display: block; margin: 0 auto;"},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n                "},{"type":"element","tag":"a","props":{"href":"https://developer.nvidia.com/cuda-downloads","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"CUDA"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n        "}]},{"type":"text","value":"\n    "}]}]},{"type":"text","value":"\n    "},{"type":"element","tag":"table","props":{"className":["w-full","text-left","table-auto","border-separate","[border-spacing:0_0.75rem]"]},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"thead","props":{"className":["text-gray-600","uppercase","text-sm","font-semibold"]},"children":[{"type":"text","value":"\n            "},{"type":"element","tag":"tr","props":{},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"th","props":{"className":["px-6","py-3","bg-blue-100","rounded-l-2xl"]},"children":[{"type":"text","value":"Component"}]},{"type":"text","value":"\n                "},{"type":"element","tag":"th","props":{"className":["px-6","py-3","bg-blue-100"]},"children":[{"type":"text","value":"Basic"}]},{"type":"text","value":"\n                "},{"type":"element","tag":"th","props":{"className":["px-6","py-3","bg-blue-100","rounded-r-2xl"]},"children":[{"type":"text","value":"Enthusiast"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n        "}]},{"type":"text","value":"\n        "},{"type":"element","tag":"tbody","props":{"className":["text-gray-800","text-base"]},"children":[{"type":"text","value":"\n            "},{"type":"element","tag":"tr","props":{"className":["bg-gray-50","hover:bg-gray-100","transition-colors","duration-200","rounded-2xl"]},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-l-2xl"]},"children":[{"type":"text","value":"\n                    "},{"type":"element","tag":"div","props":{"className":["font-medium"]},"children":[{"type":"text","value":"RAM"}]},{"type":"text","value":"\n                "}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4"]},"children":[{"type":"text","value":"16 GB"}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-r-2xl"]},"children":[{"type":"text","value":"32 GB+"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"tr","props":{"className":["bg-gray-50","hover:bg-gray-100","transition-colors","duration-200","rounded-2xl"]},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-l-2xl"]},"children":[{"type":"text","value":"\n                    "},{"type":"element","tag":"div","props":{"className":["font-medium"]},"children":[{"type":"text","value":"GPU VRAM"}]},{"type":"text","value":"\n                "}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4"]},"children":[{"type":"text","value":"8 GB"}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-r-2xl"]},"children":[{"type":"text","value":"16 GB+"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"tr","props":{"className":["bg-gray-50","hover:bg-gray-100","transition-colors","duration-200","rounded-2xl"]},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-l-2xl"]},"children":[{"type":"text","value":"\n                    "},{"type":"element","tag":"div","props":{"className":["font-medium"]},"children":[{"type":"text","value":"Storage"}]},{"type":"text","value":"\n                "}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4"]},"children":[{"type":"text","value":"50 GB SSD"}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-r-2xl"]},"children":[{"type":"text","value":"1 TB+ SSD"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"tr","props":{"className":["bg-gray-50","hover:bg-gray-100","transition-colors","duration-200","rounded-2xl"]},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-l-2xl"]},"children":[{"type":"text","value":"\n                    "},{"type":"element","tag":"div","props":{"className":["font-medium"]},"children":[{"type":"text","value":"CPU"}]},{"type":"text","value":"\n                "}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4"]},"children":[{"type":"text","value":"4+ Cores"}]},{"type":"text","value":"\n                "},{"type":"element","tag":"td","props":{"className":["px-6","py-4","rounded-r-2xl"]},"children":[{"type":"text","value":"8+ Cores"}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n        "}]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Ollama is the most important tool in this kit. It takes the complexity out of the equation and makes it easy to install, manage, and run various AI models. We will use this tool to set up an AI \"playground\" in Visual Studio Code (VS Code), which resembles a kind of lab book called a Jupyter Notebook."}]},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In the following steps, we will together:"}]},{"type":"text","value":"\n            "},{"type":"element","tag":"ul","props":{},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Install the necessary software."}]},{"type":"text","value":"\n                "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Set up your development environment so that everything is clean and organized."}]},{"type":"text","value":"\n                "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Download your first AI model and get it running with a few lines of code."}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"You don't need to be a programming expert to get started. We will guide you through every single step and provide you with all the code snippets you need."}]},{"type":"text","value":"\n            "},{"type":"element","tag":"h5","props":{"id":"a-quick-look-at-the-hardware"},"children":[{"type":"text","value":"A Quick Look at the Hardware"}]},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"You saw a table with hardware recommendations in the previous overview. It is important to understand that the performance of AI models heavily depends on your Random Access Memory (RAM) and, if you have one, on your Graphics Processing Unit (GPU)."}]},{"type":"text","value":"\n            "},{"type":"element","tag":"ul","props":{},"children":[{"type":"text","value":"\n                "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"RAM:"}]},{"type":"text","value":" This is your computer's short-term memory. The larger the AI model, the more RAM is needed to run it."}]},{"type":"text","value":"\n                "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"GPU:"}]},{"type":"text","value":" An NVIDIA graphics card can massively accelerate computational power. If you have one, the AI experience will be significantly faster. But even without a powerful GPU, you can get started it will just take a bit longer."}]},{"type":"text","value":"\n            "}]},{"type":"text","value":"\n            "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"See these recommendations as a guide, not as rigid rules. Even with a basic setup, you can experiment with smaller, yet impressive, models and learn the fundamentals."}]},{"type":"text","value":"\n        "}]},{"type":"element","tag":"div","props":{"className":["ollama-navbar-content","ollama-content-1"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"h4","props":{"id":"installation-process"},"children":[{"type":"text","value":"Installation Process"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"ol","props":{},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Install VS Code extensions: "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Python"}]},{"type":"text","value":" and "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Jupyter"}]},{"type":"text","value":" (Ctrl+Shift+X in VS Code)."}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Create a virtual Python environment: Open folder in VS Code, use "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"Python: Create Environment"}]},{"type":"text","value":" (Ctrl+Shift+P), select "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"Venv"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Install Jupyter kernel: Open terminal, run "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"pip install ipykernel"}]},{"type":"text","value":" in your virtual environment."}]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Start Ollama after installation and check if the service is running. Make sure Python and CUDA are set up correctly for optimal AI model performance. Configure your environment variables and test the installation."}]}]},{"type":"element","tag":"div","props":{"className":["ollama-navbar-content","ollama-content-2"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"h4","props":{"id":"testing-and-experimentation"},"children":[{"type":"text","value":"Testing and Experimentation"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Compare model requirements:"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"ul","props":{},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"gemma3:1b"}]},{"type":"text","value":" ‚Äì 815 MB, 4 GB RAM, Multimodal/Chat"}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"mistral:7b"}]},{"type":"text","value":" ‚Äì 4.1 GB, 8 GB RAM, Fast Chat"}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"llama2:7b"}]},{"type":"text","value":" ‚Äì 3.8 GB, 8 GB RAM, General Chat"}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"codellama:7b"}]},{"type":"text","value":" ‚Äì 3.8 GB, 8 GB RAM, Code Generation"}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"deepseek-coder:33b"}]},{"type":"text","value":" ‚Äì 18 GB, 22 GB RAM, Complex Coding"}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"llama3.1:70b"}]},{"type":"text","value":" ‚Äì 40 GB, 48 GB RAM, Advanced Reasoning"}]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tag":"ol","props":{},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Start Ollama server in a separate terminal: "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"ollama serve"}]}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Download a model: "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"ollama pull gemma3:1b"}]}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Run in Jupyter Notebook (VS Code):"}]},{"type":"element","tag":"pre","props":{"code":"    # Ensure Ollama server is running!\n    model_name = 'gemma3:1b'\n\n    try:\n        ollama.list()\n        print(\"Ollama Server reachable.\")\n\n        response = ollama.chat(\n            model=model_name,\n            messages=[\n                {\n                    'role': 'user',\n                    'content': 'Why is the sky blue? Explain simply.',\n                },\n            ]\n        )\n        print(\"\\nFull response:\")\n        print(response)\n        # Robust: Zeige die Antwort, falls das Feld existiert\n        if 'message' in response and isinstance(response['message'], dict) and 'content' in response['message']:\n            print(\"\\nModel response:\")\n            print(response['message']['content'])\n        else:\n            print(\"\\nNo valid model response found in 'message' field.\")\n    except Exception as e:\n        print(f\"\\nError: {e}\")\n        print(\"Make sure 'ollama serve' is running in a separate terminal.\")\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"    # Ensure Ollama server is running!\n    model_name = 'gemma3:1b'\n\n    try:\n        ollama.list()\n        print(\"Ollama Server reachable.\")\n\n        response = ollama.chat(\n            model=model_name,\n            messages=[\n                {\n                    'role': 'user',\n                    'content': 'Why is the sky blue? Explain simply.',\n                },\n            ]\n        )\n        print(\"\\nFull response:\")\n        print(response)\n        # Robust: Zeige die Antwort, falls das Feld existiert\n        if 'message' in response and isinstance(response['message'], dict) and 'content' in response['message']:\n            print(\"\\nModel response:\")\n            print(response['message']['content'])\n        else:\n            print(\"\\nNo valid model response found in 'message' field.\")\n    except Exception as e:\n        print(f\"\\nError: {e}\")\n        print(\"Make sure 'ollama serve' is running in a separate terminal.\")\n"}]}]}]},{"type":"text","value":"   \n"}]},{"type":"element","tag":"div","props":{"className":["ollama-navbar-content","ollama-content-3"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"h4","props":{"id":"common-issues-and-solutions"},"children":[{"type":"text","value":"Common Issues and Solutions"}]},{"type":"text","value":"\n    "},{"type":"element","tag":"ul","props":{},"children":[{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"ModuleNotFoundError: No module named 'ollama'"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n            Install "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"ollama"}]},{"type":"text","value":" in your active virtual environment: "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"pip install ollama"}]},{"type":"text","value":".\n        "}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Slow performance or high CPU usage"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n            Try smaller models (e.g., "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"gemma3:1b"}]},{"type":"text","value":"). For NVIDIA GPUs, ensure CUDA Toolkit is installed.\n        "}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Connection to Ollama server failed"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n            Make sure "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"ollama serve"}]},{"type":"text","value":" is running in a separate terminal. Check firewall settings for port 11434.\n        "}]},{"type":"text","value":"\n        "},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"CUDA conflicts or GPU not detected"}]},{"type":"element","tag":"br","props":{},"children":[]},{"type":"text","value":"\n            Update NVIDIA drivers, check CUDA version with "},{"type":"element","tag":"code","props":{},"children":[{"type":"text","value":"nvidia-smi"}]},{"type":"text","value":", and restart your system if needed.\n        "}]},{"type":"text","value":"\n    "}]},{"type":"text","value":"\n    "},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Refer to documentation or forums for further help."}]}]}]},{"type":"element","tag":"style","props":{},"children":[{"type":"text","value":"\n.ollama-navbar-tabs {\n  width: 100%;\n}\n.ollama-tab-radio {\n  display: none;\n}\n.ollama-navbar-btn {\n  /* ...bestehendes Styling... */\n}\n.ollama-navbar-content {\n  display: none;\n}\n#ollama-tab-0:checked ~ .ollama-navbar .ollama-navbar-btn[for=\"ollama-tab-0\"],\n#ollama-tab-1:checked ~ .ollama-navbar .ollama-navbar-btn[for=\"ollama-tab-1\"],\n#ollama-tab-2:checked ~ .ollama-navbar .ollama-navbar-btn[for=\"ollama-tab-2\"],\n#ollama-tab-3:checked ~ .ollama-navbar .ollama-navbar-btn[for=\"ollama-tab-3\"] {\n  background: #0056b3;\n}\n#ollama-tab-0:checked ~ .ollama-content-0,\n#ollama-tab-1:checked ~ .ollama-content-1,\n#ollama-tab-2:checked ~ .ollama-content-2,\n#ollama-tab-3:checked ~ .ollama-content-3 {\n  display: block;\n}\n"}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:articles:10.Ollama-intruduction.md","_source":"content","_file":"articles/10.Ollama-intruduction.md","_stem":"articles/10.Ollama-intruduction","_extension":"md"}