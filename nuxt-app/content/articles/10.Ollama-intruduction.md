---
cover: https://imgs.search.brave.com/8xshJuTEcdDh4ATRrUMvxIB39O6v3yf7382wqSkPcWg/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9jZG4u/YnJhbmRmZXRjaC5p/by9pZHJSRG1aMl9G/L3cvMTgwL2gvMTgw/L3RoZW1lL2xpZ2h0/L2xvZ28ucG5nP2M9/MWJ4aWQ2NE11cDdh/Y3pld1NBWU1YJnQ9/MTc0Nzc0NDA3MTE3/OA
date: 2025-07-01T00:00:00.000Z
description: How To run AI Models on your own PC + Software A1 Terminal for interact with these | Beginner/Setup Guide
layout: article_backup
---


<style>

.ollama-navbar {
  display: flex;
  gap: 1px;
  margin-bottom: 24px;
  justify-content: center;
  flex-wrap: nowrap;
  overflow-x: visible;
}
.ollama-navbar-btn {
    background: #007bff;
    color: white;
    border: none;
    border-radius: 6px 6px 0 0;
    padding: 2px 4px;
    font-size: 0.65em;
    font-weight: bold;
    cursor: pointer;
    transition: background 0.2s;
    outline: none;
    white-space: nowrap;
}
@media (max-width: 1200px) {
  .ollama-navbar-btn {
    font-size: 0.58em;
    padding: 2px 3px;
  }
}
@media (max-width: 900px) {
  .ollama-navbar-btn {
    font-size: 0.5em;
    padding: 1px 2px;
  }
}
@media (max-width: 600px) {
  .ollama-navbar-btn {
    font-size: 0.42em;
    padding: 1px 1px;
  }
}
.ollama-navbar-btn.active,
.ollama-navbar-btn:hover {
    background: #0056b3;
}
.ollama-navbar-content {
    background: #000000ff;
    border-radius: 0 0 8px 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.08);
    padding: 24px;
    margin-top: -2px;
    border-top: 1px solid #ddd;
}

/* Tabellen auf volle Breite */
table {
    width: 100% !important;
}
</style>
<div class="ollama-navbar-tabs">
<input type="radio" name="ollama-tab" id="ollama-tab-0" class="ollama-tab-radio" checked>
<input type="radio" name="ollama-tab" id="ollama-tab-1" class="ollama-tab-radio">
<input type="radio" name="ollama-tab" id="ollama-tab-2" class="ollama-tab-radio">
<input type="radio" name="ollama-tab" id="ollama-tab-3" class="ollama-tab-radio">
<input type="radio" name="ollama-tab" id="ollama-tab-4" class="ollama-tab-radio">
<div class="ollama-navbar">
    <label class="ollama-navbar-btn" for="ollama-tab-0">üß† How AI Works</label>
    <label class="ollama-navbar-btn" for="ollama-tab-1">üìã Preparation</label>
    <label class="ollama-navbar-btn" for="ollama-tab-2">‚öôÔ∏è Setup for developers</label>
    <label class="ollama-navbar-btn" for="ollama-tab-3">üí¨ A1-Terminal</label>
    <label class="ollama-navbar-btn" for="ollama-tab-4">üìñ A1-Manual</label>
</div>
<div class="ollama-navbar-content ollama-content-0">

##### ü§î What is a Large Language Model (LLM)?

A Large Language Model is an artificial intelligence system trained on vast amounts of text data to understand and generate human-like text. Think of it as a sophisticated pattern recognition system that has "read" billions of pages of text and learned the statistical relationships between words and concepts.

**Key Concepts:**

- **Neural Networks:** LLMs are built on artificial neural networks inspired by the human brain, consisting of billions of interconnected nodes (parameters)
- **Training:** Models learn by processing massive datasets, adjusting their internal parameters to predict the next word in a sequence
- **Inference:** When you ask a question, the model uses its learned patterns to generate a relevant response word by word


##### üîí Why Run AI Locally?

**Privacy:** Your data never leaves your computer - no cloud servers, no logging  
**Cost:** No API fees or subscription costs after initial setup  
**Customization:** Full control over model behavior and system prompts  
**Offline:** Works without internet connection  
**Learning:** Understand how AI systems actually work


##### üìä Model Sizes and Parameters

The "size" of a model refers to the number of parameters (weights) it contains:

| Model Size | Parameters | RAM Required | Example Models |
|------------|------------|--------------|----------------|
| Tiny | 1-2B | 4-8 GB | tinyllama:1.1b, gemma:2b |
| Small | 3-7B | 8-16 GB | phi3:mini, llama3.2:3b, mistral:7b |
| Medium | 13-34B | 24-48 GB | llama2:13b, codellama:34b |
| Large | 70B+ | 80+ GB | llama3.1:70b, mixtral:8x7b |

**More parameters ‚â† Always better:** Smaller, well-trained models can outperform larger ones for specific tasks.

##### ‚öôÔ∏è How Does Text Generation Work?

1. **Tokenization:** Your input text is split into "tokens" (roughly words or word parts)
2. **Embedding:** Each token is converted into a numerical vector
3. **Processing:** These vectors flow through multiple neural network layers
4. **Prediction:** The model calculates probability scores for the next token
5. **Sampling:** A token is selected based on these probabilities (with some randomness for creativity)
6. **Repeat:** Steps 3-5 continue until the response is complete

**Example:**
```
Input: "The capital of France is"
Model thinks: "Paris" (95%), "Lyon" (2%), "Marseille" (1%)...
Output: "Paris"
```

##### üéØ Temperature and Sampling

**Temperature** controls the randomness of responses:

- **Temperature 0.0:** Deterministic, always picks the most likely token (good for factual answers)
- **Temperature 0.7:** Balanced creativity and coherence (default for most tasks)
- **Temperature 1.0+:** More creative/random (good for storytelling, brainstorming)

**Top-K & Top-P Sampling:** Additional techniques to control output quality by limiting which tokens can be selected.

##### üèãÔ∏è CPU vs GPU Processing

**Why GPUs are faster:**

- **Parallel Processing:** GPUs have thousands of cores that can process many calculations simultaneously
- **Matrix Operations:** AI models require massive matrix multiplications, which GPUs excel at
- **VRAM:** GPU memory is faster than system RAM for neural network operations

**CPU Processing:**
- Uses system RAM
- Processes calculations sequentially (or with limited parallelism)
- Works perfectly fine but slower (seconds vs milliseconds per token)

**Practical Impact:**
- **CPU:** 3-10 tokens/second (small models)
- **GPU (8GB):** 20-50 tokens/second
- **GPU (16GB+):** 50-100+ tokens/second

##### üéì Common Misconceptions

‚ùå **"AI understands like humans do"**  
‚úÖ AI recognizes patterns in text but doesn't "understand" meaning in a human sense

‚ùå **"Bigger models are always better"**  
‚úÖ Smaller specialized models often perform better for specific tasks

‚ùå **"AI needs GPU to work"**  
‚úÖ CPU-only operation is perfectly viable, just slower

‚ùå **"AI is always accurate"**  
‚úÖ Models can "hallucinate" (generate plausible-sounding but incorrect information)

##### üìö Recommended Reading

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762){target="_blank"} - The transformer paper that revolutionized AI
- [Ollama Documentation](https://github.com/ollama/ollama/tree/main/docs){target="_blank"} - Technical details about local model deployment
- [Hugging Face Model Hub](https://huggingface.co/models){target="_blank"} - Explore available AI models

**Ready to get started?** Check the next tabs for installation and setup instructions!

</div>

<div class="ollama-navbar-content ollama-content-1">
        <div style="margin-top: 24px; margin-bottom: 24px;">
            <h4>Before You Begin</h4>
            <p>This guide provides an introduction to running AI models locally on your computer. You'll learn how to work with Large Language Models (LLMs) using tools like Ollama, Jupyter Notebooks, and Python virtual environments.</p>
            <p>Running AI models locally offers several advantages: full control over your data, enhanced privacy, no dependency on internet connectivity, and no recurring cloud service costs. This approach is particularly valuable for academic work, research projects, and learning the fundamentals of AI implementation.</p>
        </div>
    <table>
        <tr>
            <td align="center" style="width: 180px;">
                <img src="https://imgs.search.brave.com/V2oVVCsPaNxkGlhMMz5AxhgzgEvkZRmyQf3x22R5ebQ/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9hc3Nl/dHMuc3RpY2twbmcu/Y29tL2ltYWdlcy82/MmE3OTA2Y2U0MmQ3/MjlkOTI4YjE3NTcu/cG5n" alt="VS Code Logo" style="max-width: 100px; max-height: 80px; display: block; margin: 0 auto;">
                <br>
                <a href="https://code.visualstudio.com/download" target="_blank" rel="noopener">VS Code</a>
            </td>
            <td align="center" style="width: 180px;">
                <img src="https://www.python.org/static/community_logos/python-logo.png" alt="Python Logo" style="max-width: 100px; max-height: 80px; display: block; margin: 0 auto;">
                <br>
                <a href="https://www.python.org/downloads/" target="_blank" rel="noopener">Python</a>
            </td>
            <td align="center" style="width: 180px;">
                <img src="https://imgs.search.brave.com/8xshJuTEcdDh4ATRrUMvxIB39O6v3yf7382wqSkPcWg/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9jZG4u/YnJhbmRmZXRjaC5p/by9pZHJSRG1aMl9G/L3cvMTgwL2gvMTgw/L3RoZW1lL2xpZ2h0/L2xvZ28ucG5nP2M9/MWJ4aWQ2NE11cDdh/Y3pld1NBWU1YJnQ9/MTc0Nzc0NDA3MTE3/OA" alt="Ollama Logo" style="max-width: 100px; max-height: 80px; display: block; margin: 0 auto;">
                <br>
                <a href="https://ollama.com/download" target="_blank" rel="noopener">Ollama</a>
            </td>
            <td align="center" style="width: 180px;">
                <img src="https://imgs.search.brave.com/zLvtdX6w_dNUl6wAzFN-0BCdZQrJu7VkSySkbESjtsc/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly91cGxv/YWQud2lraW1lZGlh/Lm9yZy93aWtpcGVk/aWEvY29tbW9ucy9i/L2I5L052aWRpYV9D/VURBX0xvZ28uanBn" alt="CUDA Logo" style="max-width: 100px; max-height: 80px; display: block; margin: 0 auto;">
                <br>
                <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">CUDA</a>
            </td>
        </tr>
    </table>
    <table class="w-full text-left table-auto border-separate [border-spacing:0_0.75rem]">
        <thead class="text-gray-600 uppercase text-sm font-semibold">
            <tr>
                <th class="px-6 py-3 bg-blue-100 rounded-l-2xl">Component</th>
                <th class="px-6 py-3 bg-blue-100">Minimal</th>
                <th class="px-6 py-3 bg-blue-100">Basic</th>
                <th class="px-6 py-3 bg-blue-100 rounded-r-2xl">Enthusiast</th>
            </tr>
        </thead>
        <tbody class="text-gray-800 text-base">
            <tr class="bg-gray-50 hover:bg-gray-100 transition-colors duration-200 rounded-2xl">
                <td class="px-6 py-4 rounded-l-2xl">
                    <div class="font-medium">RAM</div>
                </td>
                <td class="px-6 py-4">4-8 GB</td>
                <td class="px-6 py-4">16 GB</td>
                <td class="px-6 py-4 rounded-r-2xl">32 GB+</td>
            </tr>
            <tr class="bg-gray-50 hover:bg-gray-100 transition-colors duration-200 rounded-2xl">
                <td class="px-6 py-4 rounded-l-2xl">
                    <div class="font-medium">GPU VRAM</div>
                </td>
                <td class="px-6 py-4">Optional / CPU only</td>
                <td class="px-6 py-4">8 GB</td>
                <td class="px-6 py-4 rounded-r-2xl">16 GB+</td>
            </tr>
            <tr class="bg-gray-50 hover:bg-gray-100 transition-colors duration-200 rounded-2xl">
                <td class="px-6 py-4 rounded-l-2xl">
                    <div class="font-medium">Storage</div>
                </td>
                <td class="px-6 py-4">10 GB free</td>
                <td class="px-6 py-4">50 GB SSD</td>
                <td class="px-6 py-4 rounded-r-2xl">1 TB+ SSD</td>
            </tr>
            <tr class="bg-gray-50 hover:bg-gray-100 transition-colors duration-200 rounded-2xl">
                <td class="px-6 py-4 rounded-l-2xl">
                    <div class="font-medium">CPU</div>
                </td>
                <td class="px-6 py-4">2+ Cores</td>
                <td class="px-6 py-4">4+ Cores</td>
                <td class="px-6 py-4 rounded-r-2xl">8+ Cores</td>
            </tr>
            <tr class="bg-gray-50 hover:bg-gray-100 transition-colors duration-200 rounded-2xl">
                <td class="px-6 py-4 rounded-l-2xl">
                    <div class="font-medium">Suitable Models</div>
                </td>
                <td class="px-6 py-4">tinyllama:1.1b<br>gemma:2b<br>phi3:mini</td>
                <td class="px-6 py-4">llama3.2:3b<br>mistral:7b<br>codellama:7b</td>
                <td class="px-6 py-4">llama3.1:70b<br>mixtral:8x7b<br>command-r:35b</td>
            </tr>
        </tbody>
    </table>
    <p>     </p>
            <p>Ollama serves as the primary interface for managing and running AI models locally. It simplifies the process of installing, configuring, and executing various language models. This guide demonstrates how to configure a development environment using Visual Studio Code (VS Code) and Jupyter Notebooks for interactive AI experimentation.</p>
            <p>The following sections cover:</p>
            <ul>
                <li>Software installation and configuration</li>
                <li>Development environment setup with proper isolation using virtual environments</li>
                <li>Initial model deployment and execution</li>
            </ul>
            <p>Each step includes detailed instructions and code examples. Prior programming experience is helpful but not required, as all necessary commands and configurations are provided.</p>
            <h5>A Quick Look at the Hardware</h5>
            <p>The hardware requirements table provides recommended specifications for different use cases. Performance of AI models is primarily determined by available Random Access Memory (RAM) and, optionally, Graphics Processing Unit (GPU) capabilities.</p>
            <ul>
                <li><strong>RAM:</strong> The system's primary memory allocation directly affects which model sizes can be loaded and executed. Larger models require proportionally more RAM.</li>
                <li><strong>GPU:</strong> NVIDIA graphics cards with CUDA support can significantly accelerate inference times. GPU acceleration is optional and provides performance benefits but is not required for basic operation.</li>
                <li><strong>CPU-Only Operation:</strong> GPU hardware is not mandatory. Ollama functions on CPU-only systems with standard configurations. Smaller models (e.g., <code>tinyllama:1.1b</code>, <code>phi3:mini</code>, <code>gemma:2b</code>) operate efficiently on systems with 4-8GB RAM. Response generation is slower compared to GPU-accelerated setups but remains practical for learning and development purposes.</li>
            </ul>
            <p>These specifications serve as guidelines rather than strict requirements. Entry-level hardware configurations are sufficient for experimentation with compact models and learning fundamental concepts. CUDA installation is only necessary for leveraging NVIDIA GPU acceleration and can be omitted for CPU-based workflows.</p>
            <h5>üöÄ Quick Start with A1-Terminal</h5>
            <p><strong>Want to skip manual setup?</strong> The A1-Terminal project includes automatic installation scripts that handle everything for you!</p>
            <p>The installation scripts automatically install:</p>
            <ul>
                <li>‚úÖ <strong>Python 3.11+</strong> (if not already present)</li>
                <li>‚úÖ <strong>Ollama</strong> service and API</li>
                <li>‚úÖ <strong>All required Python packages</strong> (customtkinter, ollama, PyYAML, requests, pyperclip)</li>
                <li>‚úÖ <strong>Test model</strong> (tinyllama:1.1b) to get started immediately</li>
                <li>‚ö†Ô∏è <strong>CUDA</strong> must be installed manually (only needed for NVIDIA GPU acceleration)</li>
            </ul>
            <p><strong>Perfect for:</strong> Beginners who want a working setup immediately, or anyone who prefers using a modern GUI instead of command-line tools.</p>
            <p>üìñ <strong>See the "A1-Terminal" tab above for complete installation instructions and features.</strong></p>
        </div>

        
<div class="ollama-navbar-content ollama-content-2">

##### üì¶ Required Software Components

<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 24px; margin: 24px 0;">
  
  <div style="background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%); padding: 24px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
    <h3 style="color: white; margin-top: 0; display: flex; align-items: center; gap: 8px;">
      üêç <span>Python 3.8+</span>
    </h3>
    <ul style="color: white; line-height: 1.8;">
      <li>Download from <a href="https://www.python.org/downloads/" target="_blank" style="color: #93c5fd; text-decoration: underline;">python.org</a></li>
      <li>During installation: ‚úÖ Check "Add Python to PATH"</li>
      <li>Verify installation: <code style="background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 4px;">python --version</code></li>
      <li>Includes <strong>pip</strong> (Python package manager)</li>
    </ul>
  </div>

  <div style="background: linear-gradient(135deg, #7c3aed 0%, #a78bfa 100%); padding: 24px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
    <h3 style="color: white; margin-top: 0; display: flex; align-items: center; gap: 8px;">
      ü¶ô <span>Ollama</span>
    </h3>
    <ul style="color: white; line-height: 1.8;">
      <li>Download from <a href="https://ollama.com/download" target="_blank" style="color: #e9d5ff; text-decoration: underline;">ollama.com</a></li>
      <li>Runs as background service on <code style="background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 4px;">localhost:11434</code></li>
      <li>Verify: <code style="background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 4px;">ollama --version</code></li>
      <li>Start service: <code style="background: rgba(0,0,0,0.3); padding: 2px 6px; border-radius: 4px;">ollama serve</code> (automatic on Windows/macOS)</li>
    </ul>
  </div>

  <div style="background: linear-gradient(135deg, #0891b2 0%, #06b6d4 100%); padding: 24px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
    <h3 style="color: white; margin-top: 0; display: flex; align-items: center; gap: 8px;">
      üíª <span>Visual Studio Code</span>
    </h3>
    <ul style="color: white; line-height: 1.8;">
      <li>Download from <a href="https://code.visualstudio.com/" target="_blank" style="color: #cffafe; text-decoration: underline;">code.visualstudio.com</a></li>
      <li><strong>Required Extensions</strong> (Ctrl+Shift+X):</li>
      <li style="margin-left: 20px;">‚Üí <strong>Python</strong> (ms-python.python) - Python IntelliSense & debugging</li>
      <li style="margin-left: 20px;">‚Üí <strong>Jupyter</strong> (ms-toolsai.jupyter) - Interactive notebooks</li>
    </ul>
  </div>

  <div style="background: linear-gradient(135deg, #15803d 0%, #22c55e 100%); padding: 24px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
    <h3 style="color: white; margin-top: 0; display: flex; align-items: center; gap: 8px;">
      ‚ö° <span>CUDA Toolkit</span> <span style="font-size: 0.7em; background: rgba(255,255,255,0.3); padding: 2px 8px; border-radius: 4px;">Optional</span>
    </h3>
    <ul style="color: white; line-height: 1.8;">
      <li>Download from <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" style="color: #d9f99d; text-decoration: underline;">NVIDIA CUDA Downloads</a></li>
      <li>Required <strong>only</strong> for GPU acceleration with NVIDIA graphics cards</li>
      <li>Significantly improves inference speed</li>
      <li>Skip if using CPU-only or AMD GPUs</li>
    </ul>
  </div>

</div>

---

##### üîß Development Environment Setup

###### Step 1: Install VS Code Extensions
1. Open VS Code
2. Press `Ctrl+Shift+X` (Extensions)
3. Search and install: **Python** and **Jupyter**

###### Step 2: Create Virtual Environment
1. Open your project folder in VS Code
2. Press `Ctrl+Shift+P` (Command Palette)
3. Type: `Python: Create Environment`
4. Select **Venv**
5. Choose your Python interpreter

**Why virtual environments?** Isolates project dependencies, prevents version conflicts, and keeps your system Python clean.

###### Step 3: Install Jupyter Kernel
Open integrated terminal (`Ctrl+\``) and run:
```bash
pip install ipykernel
```
This enables Jupyter notebooks to use your virtual environment.

###### Step 4: Verify Ollama Service
Check if Ollama is running:
```bash
ollama list
```
If not running, start it:
```bash
ollama serve
```

###### Step 5: Download Your First Model
```bash
ollama pull tinyllama:1.1b
```
---

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 20px; margin: 24px 0;">

<!-- Ultra-Lightweight Category -->
<div style="background: linear-gradient(135deg, #00695c 0%, #00897b 100%); padding: 18px; border-radius: 10px; border: 1px solid #00e676; box-shadow: 0 4px 8px rgba(0,230,118,0.3);">
  <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 14px;">
    <span style="font-size: 24px;">‚ö°</span>
    <h4 style="margin: 0; color: #ffffff; font-size: 1em; font-weight: 600;">Ultra-Lightweight (1-2B)</h4>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 3px; font-size: 0.9em;">tinyllama:1.1b ‚úÖ</div>
    <div style="font-size: 0.78em; color: #b2dfdb; line-height: 1.3;">
      <strong>Size:</strong> 600 MB | <strong>RAM:</strong> 4 GB<br>
      <strong>Use:</strong> Quick tests, learning basics<br>
      <strong>Speed:</strong> Very fast, CPU-friendly
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/gemma:2b" target="_blank" style="color: #69f0ae; text-decoration: none;">gemma:2b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #b2dfdb; line-height: 1.3;">
      <strong>Size:</strong> 1.4 GB | <strong>RAM:</strong> 4-6 GB<br>
      <strong>Use:</strong> Google's efficient model<br>
      <strong>Quality:</strong> Great size/performance ratio
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/qwen2.5:1.5b" target="_blank" style="color: #69f0ae; text-decoration: none;">qwen2.5:1.5b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #b2dfdb; line-height: 1.3;">
      <strong>Size:</strong> 930 MB | <strong>RAM:</strong> 4 GB<br>
      <strong>Use:</strong> Multilingual, fast responses<br>
      <strong>Quality:</strong> Modern architecture, efficient
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/phi3.5:mini" target="_blank" style="color: #69f0ae; text-decoration: none;">phi3.5:mini üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #b2dfdb; line-height: 1.3;">
      <strong>Size:</strong> 2.2 GB | <strong>RAM:</strong> 6 GB<br>
      <strong>Use:</strong> Advanced reasoning<br>
      <strong>Quality:</strong> Microsoft's latest compact
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; border-left: 3px solid #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/smollm:1.7b" target="_blank" style="color: #69f0ae; text-decoration: none;">smollm:1.7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #b2dfdb; line-height: 1.3;">
      <strong>Size:</strong> 1 GB | <strong>RAM:</strong> 4 GB<br>
      <strong>Use:</strong> Edge devices, mobile-friendly<br>
      <strong>Quality:</strong> Lightweight applications
    </div>
  </div>
</div>

<!-- Balanced Category -->
<div style="background: linear-gradient(135deg, #0277bd 0%, #0288d1 100%); padding: 18px; border-radius: 10px; border: 1px solid #00b0ff; box-shadow: 0 4px 8px rgba(0,176,255,0.3);">
  <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 14px;">
    <span style="font-size: 24px;">‚öñÔ∏è</span>
    <h4 style="margin: 0; color: #ffffff; font-size: 1em; font-weight: 600;">Balanced (3-7B)</h4>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/phi3:mini" target="_blank" style="color: #40c4ff; text-decoration: none;">phi3:mini üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #81d4fa; line-height: 1.3;">
      <strong>Size:</strong> 2.3 GB | <strong>RAM:</strong> 8 GB<br>
      <strong>Use:</strong> General chat, reasoning tasks<br>
      <strong>Quality:</strong> Microsoft, excellent value
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/llama3.2:3b" target="_blank" style="color: #40c4ff; text-decoration: none;">llama3.2:3b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #81d4fa; line-height: 1.3;">
      <strong>Size:</strong> 2 GB | <strong>RAM:</strong> 8 GB<br>
      <strong>Use:</strong> Latest Meta model, versatile<br>
      <strong>Quality:</strong> Top tier for 3B class
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/mistral:7b" target="_blank" style="color: #40c4ff; text-decoration: none;">mistral:7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #81d4fa; line-height: 1.3;">
      <strong>Size:</strong> 4.1 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> High-quality responses<br>
      <strong>Quality:</strong> Industry standard, proven
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/qwen2.5:7b" target="_blank" style="color: #40c4ff; text-decoration: none;">qwen2.5:7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #81d4fa; line-height: 1.3;">
      <strong>Size:</strong> 4.7 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> Advanced reasoning, multilingual<br>
      <strong>Quality:</strong> State-of-the-art performance
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/llama3.1:8b" target="_blank" style="color: #40c4ff; text-decoration: none;">llama3.1:8b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #81d4fa; line-height: 1.3;">
      <strong>Size:</strong> 4.7 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> Tool calling, extended context<br>
      <strong>Quality:</strong> 128K tokens context
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; border-left: 3px solid #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/gemma2:9b" target="_blank" style="color: #40c4ff; text-decoration: none;">gemma2:9b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #81d4fa; line-height: 1.3;">
      <strong>Size:</strong> 5.4 GB | <strong>RAM:</strong> 14 GB<br>
      <strong>Use:</strong> Research, creative writing<br>
      <strong>Quality:</strong> Google's powerful model
    </div>
  </div>
</div>

<!-- Code Specialist Category -->
<div style="background: linear-gradient(135deg, #6a1b9a 0%, #7b1fa2 100%); padding: 18px; border-radius: 10px; border: 1px solid #e040fb; box-shadow: 0 4px 8px rgba(224,64,251,0.3);">
  <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 14px;">
    <span style="font-size: 24px;">üíª</span>
    <h4 style="margin: 0; color: #ffffff; font-size: 1em; font-weight: 600;">Code Specialist</h4>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/codegemma:2b" target="_blank" style="color: #ea80fc; text-decoration: none;">codegemma:2b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ce93d8; line-height: 1.3;">
      <strong>Size:</strong> 1.6 GB | <strong>RAM:</strong> 6 GB<br>
      <strong>Use:</strong> Lightweight code helper<br>
      <strong>Languages:</strong> Python, JS, Java, C++
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/codellama:7b" target="_blank" style="color: #ea80fc; text-decoration: none;">codellama:7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ce93d8; line-height: 1.3;">
      <strong>Size:</strong> 3.8 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> Code generation, debugging<br>
      <strong>Quality:</strong> Meta, reliable for coding
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/qwen2.5-coder:7b" target="_blank" style="color: #ea80fc; text-decoration: none;">qwen2.5-coder:7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ce93d8; line-height: 1.3;">
      <strong>Size:</strong> 4.7 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> Advanced code tasks<br>
      <strong>Quality:</strong> Top coding model in 7B class
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/deepseek-coder:6.7b" target="_blank" style="color: #ea80fc; text-decoration: none;">deepseek-coder:6.7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ce93d8; line-height: 1.3;">
      <strong>Size:</strong> 3.8 GB | <strong>RAM:</strong> 10 GB<br>
      <strong>Use:</strong> Code completion, refactoring<br>
      <strong>Quality:</strong> Specialized for development
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/starcoder2:3b" target="_blank" style="color: #ea80fc; text-decoration: none;">starcoder2:3b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ce93d8; line-height: 1.3;">
      <strong>Size:</strong> 1.7 GB | <strong>RAM:</strong> 6 GB<br>
      <strong>Use:</strong> Fast code completion<br>
      <strong>Languages:</strong> 600+ programming languages
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; border-left: 3px solid #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/granite-code:8b" target="_blank" style="color: #ea80fc; text-decoration: none;">granite-code:8b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ce93d8; line-height: 1.3;">
      <strong>Size:</strong> 4.6 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> Enterprise code generation<br>
      <strong>Quality:</strong> IBM's code specialist
    </div>
  </div>
</div>

<!-- German Language Category -->
<div style="background: linear-gradient(135deg, #f57c00 0%, #fb8c00 100%); padding: 18px; border-radius: 10px; border: 1px solid #ff9100; box-shadow: 0 4px 8px rgba(255,145,0,0.3);">
  <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 14px;">
    <span style="font-size: 24px;">üá©üá™</span>
    <h4 style="margin: 0; color: #ffffff; font-size: 1em; font-weight: 600;">German Optimized</h4>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/llama3.2:3b" target="_blank" style="color: #ffab40; text-decoration: none;">llama3.2:3b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ffcc80; line-height: 1.3;">
      <strong>Size:</strong> 2 GB | <strong>RAM:</strong> 8 GB<br>
      <strong>Use:</strong> Multilingual, strong German<br>
      <strong>Quality:</strong> Best 3B for German tasks
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/mistral:7b" target="_blank" style="color: #ffab40; text-decoration: none;">mistral:7b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ffcc80; line-height: 1.3;">
      <strong>Size:</strong> 4.1 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> Professional German output<br>
      <strong>Quality:</strong> Excellent German support
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; margin-bottom: 8px; border-left: 3px solid #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/aya:8b" target="_blank" style="color: #ffab40; text-decoration: none;">aya:8b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ffcc80; line-height: 1.3;">
      <strong>Size:</strong> 4.8 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use:</strong> 101 languages incl. German<br>
      <strong>Quality:</strong> Multilingual specialist
    </div>
  </div>
  
  <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 6px; border-left: 3px solid #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 3px; font-size: 0.9em;">
      <a href="https://ollama.com/library/gemma2:9b" target="_blank" style="color: #ffab40; text-decoration: none;">gemma2:9b üîó</a>
    </div>
    <div style="font-size: 0.78em; color: #ffcc80; line-height: 1.3;">
      <strong>Size:</strong> 5.4 GB | <strong>RAM:</strong> 14 GB<br>
      <strong>Use:</strong> High-quality German conversations<br>
      <strong>Quality:</strong> Google's powerful multilingual
    </div>
  </div>
</div>

</div>

<div style="background: linear-gradient(135deg, #004d40 0%, #00695c 100%); padding: 14px; border-radius: 8px; border-left: 4px solid #4db6ac; margin-top: 16px;">
  <strong style="color: #b2dfdb;">üí° Quick Start:</strong> <span style="color: #e0f2f1;">Begin with <code style="background: rgba(0,0,0,0.4); padding: 2px 6px; border-radius: 3px;">tinyllama:1.1b</code> (included) or <code style="background: rgba(0,0,0,0.4); padding: 2px 6px; border-radius: 3px;">phi3:mini</code> for best balance. Download models in A1-Terminal's "Models" tab or via CLI: <code style="background: rgba(0,0,0,0.4); padding: 2px 6px; border-radius: 3px;">ollama pull model-name</code></span>
</div>


---

##### ‚úÖ Verification Checklist
- ‚úÖ Python installed and in PATH: `python --version`
- ‚úÖ Ollama service running: `ollama list`
- ‚úÖ At least one model downloaded: `ollama list`
- ‚úÖ VS Code extensions installed: Python + Jupyter
- ‚úÖ Virtual environment created and activated
- ‚úÖ Jupyter kernel installed: `pip list | grep ipykernel`

**üéØ Next Steps:** Your environment is ready! Start experimenting with Jupyter notebooks or launch A1-Terminal for a full-featured chat interface.

</div>

<div class="ollama-navbar-content ollama-content-3">

#### A1-Terminal: [H-Term](https://www.der-hammer.info/pages/terminal.html) for AI Models
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin: 16px 0;">
    <!-- A1-Terminal Repository -->
    <div style="padding: 16px; background: linear-gradient(135deg, #025709ff 0%, #05fa1aff 100%); border-radius: 12px; border: 1px solid #010202ff; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
        <div style="display: flex; align-items: center; gap: 12px;">
            <div style="background: #ffffff; border-radius: 50%; width: 48px; height: 48px; display: flex; align-items: center; justify-content: center; box-shadow: 0 2px 6px rgba(0,0,0,0.2);">
                <svg height="32" width="32" viewBox="0 0 16 16" style="fill: #24292e;">
                    <path d="M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z"></path>
                </svg>
            </div>
            <div>
                <div style="font-weight: bold; color: #24292e; font-size: 1.1em;">
                    üñ•Ô∏è A1-Terminal v1.0
                </div>
                <div style="margin-top: 4px;">
                    <a href="https://github.com/Nr44suessauer/A1-Terminal/tree/Release-Version-1.0" target="_blank" style="color: #0366d6; text-decoration: none; font-weight: 500;">Nr44suessauer/A1-Terminal</a>
                </div>
                <div style="margin-top: 8px; color: #000000ff; font-size: 0.9em; line-height: 1.5;">
                    Desktop GUI application for local AI models. Features automatic installation, session management, and complete offline privacy. Perfect for beginners and local development.
                </div>
            </div>
        </div>
    </div>
    <!-- Open WebUI Repository -->
    <div style="padding: 16px; background: linear-gradient(135deg, #1a1f2e 0%, #2d3748 100%); border-radius: 12px; border: 1px solid #4a5568; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
        <div style="display: flex; align-items: center; gap: 12px;">
            <div style="background: #ffffff; border-radius: 50%; width: 48px; height: 48px; display: flex; align-items: center; justify-content: center; box-shadow: 0 2px 6px rgba(0,0,0,0.2);">
                <svg height="32" width="32" viewBox="0 0 16 16" style="fill: #24292e;">
                    <path d="M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z"></path>
                </svg>
            </div>
            <div>
                <div style="font-weight: bold; color: #e2e8f0; font-size: 1.1em;">
                    üåê Open WebUI
                </div>
                <div style="margin-top: 4px;">
                    <a href="https://github.com/open-webui/open-webui" target="_blank" style="color: #60a5fa; text-decoration: none; font-weight: 500;">open-webui/open-webui</a>
                    <span style="color: #94a3b8; margin: 0 8px;">|</span>
                    <a href="https://openwebui.com/" target="_blank" style="color: #60a5fa; text-decoration: none; font-weight: 500;">openwebui.com</a>
                </div>
                <div style="margin-top: 8px; color: #cbd5e1; font-size: 0.9em; line-height: 1.5;">
                    Web-based interface for local AI models with Docker support, multi-user capabilities, RAG functionality, and enterprise-grade features. Ideal for advanced users and team environments.
                </div>
            </div>
        </div>
    </div>
</div>

##### üöÄ Automatic Installation (Recommended)

The installation script handles **everything automatically** - perfect for beginners or blank systems!

<div class="install-tabs">
  <input type="radio" name="auto-install" id="auto-windows" class="tab-input" checked>
  <input type="radio" name="auto-install" id="auto-linux" class="tab-input">
  
  <div class="tab-buttons">
    <label for="auto-windows" class="tab-button">ü™ü Windows</label>
    <label for="auto-linux" class="tab-button">üêßüçé Linux/macOS</label>
  </div>
  
  <div class="tab-content" id="auto-windows-content">

**Windows Installation**

```powershell
# 1. Clone repository
git clone https://github.com/Nr44suessauer/A1-Terminal.git
cd A1-Terminal

# 2. Run as Administrator (Right-click ‚Üí "Run as Administrator")
.\scripts\install.bat
```

**What the install.bat script does:**

- **Python Installation** - Checks for Python 3.11+, downloads and installs if missing
- **pip Update** - Updates Python package manager to latest version
- **Python Packages** - Installs all required packages from `requirements.txt`
- **Ollama Installation** - Downloads (~500 MB) and installs Ollama service
- **Test Model** - Downloads `tinyllama:1.1b` (~600 MB) for immediate use

**After installation:**

```powershell
cd a1_terminal_modular
.\start.bat
```

  </div>
  
  <div class="tab-content" id="auto-linux-content">

**Linux/macOS Installation**

```bash
# 1. Clone repository
git clone https://github.com/Nr44suessauer/A1-Terminal.git
cd A1-Terminal

# 2. Make executable and run
chmod +x scripts/install.sh
./scripts/install.sh
```

**What the install.sh script does:**

- **Python Installation** - Uses system package manager (apt/dnf/yum/brew)
- **pip Update** - Updates pip to latest version
- **Python Packages** - Installs all dependencies
- **Ollama** - Downloads and configures Ollama + test model

**After installation:**

```bash
cd a1_terminal_modular
./start.sh
```

  </div>
</div>

**‚è±Ô∏è Installation takes 5-10 minutes. Everything is automatic!**

---

##### üîß Manual Installation (Advanced)

For full control over each installation step:

<div class="install-tabs">
  <input type="radio" name="manual-install" id="manual-windows" class="tab-input" checked>
  <input type="radio" name="manual-install" id="manual-linux" class="tab-input">
  
  <div class="tab-buttons">
    <label for="manual-windows" class="tab-button">ü™ü Windows</label>
    <label for="manual-linux" class="tab-button">üêßüçé Linux/macOS</label>
  </div>
  
  <div class="tab-content" id="manual-windows-content">

**Windows Manual Installation**

```powershell
# 1. Install Ollama manually
# Visit https://ollama.com/download

# 2. Clone repository
git clone https://github.com/Nr44suessauer/A1-Terminal.git
cd A1-Terminal/a1_terminal_modular

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Download a model (optional)
ollama pull tinyllama:1.1b

# 5. Start application
python main.py
# Or use start script:
# .\start.bat
```

  </div>
  
  <div class="tab-content" id="manual-linux-content">

**Linux/macOS Manual Installation**

```bash
# 1. Install Ollama manually
# Visit https://ollama.com/download
# Or use: curl -fsSL https://ollama.com/install.sh | sh

# 2. Clone repository
git clone https://github.com/Nr44suessauer/A1-Terminal.git
cd A1-Terminal/a1_terminal_modular

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Download a model (optional)
ollama pull tinyllama:1.1b

# 5. Start application
python3 main.py
# Or use start script:
# ./start.sh
```

  </div>
</div>

---


#####  Recommended Models

After installation, **tinyllama:1.1b** is ready. Browse models by category:

<style>
.model-tab-radio { display: none; }
.model-tabs {
  display: flex;
  flex-wrap: wrap;
  gap: 4px;
  margin-bottom: 0;
}
.model-tab-btn {
  background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);
  color: #b0b0b0;
  border: 1px solid #404040;
  padding: 12px 20px;
  cursor: pointer;
  transition: all 0.3s;
  border-radius: 8px 8px 0 0;
  font-weight: 600;
  font-size: 0.9em;
  display: flex;
  align-items: center;
  gap: 8px;
  white-space: nowrap;
}
.model-tab-btn:hover {
  background: linear-gradient(135deg, #2d2d2d 0%, #3d3d3d 100%);
  color: #e0e0e0;
}
.model-tab-radio:checked + .model-tab-btn {
  background: linear-gradient(135deg, #00695c 0%, #00897b 100%);
  color: #ffffff;
  border-bottom: 3px solid #00e676;
  box-shadow: 0 2px 8px rgba(0, 230, 118, 0.3);
}
.model-tab-radio#model-tab-1:checked + .model-tab-btn {
  background: linear-gradient(135deg, #0277bd 0%, #0288d1 100%);
  color: #ffffff;
  border-bottom: 3px solid #00b0ff;
  box-shadow: 0 2px 8px rgba(0, 176, 255, 0.3);
}
.model-tab-radio#model-tab-2:checked + .model-tab-btn {
  background: linear-gradient(135deg, #6a1b9a 0%, #7b1fa2 100%);
  color: #ffffff;
  border-bottom: 3px solid #e040fb;
  box-shadow: 0 2px 8px rgba(224, 64, 251, 0.3);
}
.model-tab-radio#model-tab-3:checked + .model-tab-btn {
  background: linear-gradient(135deg, #f57c00 0%, #fb8c00 100%);
  color: #ffffff;
  border-bottom: 3px solid #ff9100;
  box-shadow: 0 2px 8px rgba(255, 145, 0, 0.3);
}
.model-tab-radio#model-tab-4:checked + .model-tab-btn {
  background: linear-gradient(135deg, #424242 0%, #616161 100%);
  color: #ffffff;
  border-bottom: 3px solid #bdbdbd;
  box-shadow: 0 2px 8px rgba(189, 189, 189, 0.3);
}
.model-tab-content {
  display: none;
  padding: 24px;
  background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);
  border: 1px solid #404040;
  border-radius: 0 0 12px 12px;
  margin-top: -1px;
}
.model-tab-radio:checked ~ .model-tabs-container .model-content-0 { display: none; }
.model-tab-radio:checked ~ .model-tabs-container .model-content-1 { display: none; }
.model-tab-radio:checked ~ .model-tabs-container .model-content-2 { display: none; }
.model-tab-radio:checked ~ .model-tabs-container .model-content-3 { display: none; }
.model-tab-radio:checked ~ .model-tabs-container .model-content-4 { display: none; }
#model-tab-0:checked ~ .model-tabs-container .model-content-0 { display: block; }
#model-tab-1:checked ~ .model-tabs-container .model-content-1 { display: block; }
#model-tab-2:checked ~ .model-tabs-container .model-content-2 { display: block; }
#model-tab-3:checked ~ .model-tabs-container .model-content-3 { display: block; }
#model-tab-4:checked ~ .model-tabs-container .model-content-4 { display: block; }
.model-card {
  background: rgba(0,0,0,0.4);
  padding: 16px;
  border-radius: 8px;
  margin-bottom: 12px;
  border-left: 3px solid;
  transition: transform 0.2s, box-shadow 0.2s;
}
.model-card:hover {
  transform: translateX(4px);
  box-shadow: 0 4px 12px rgba(0,0,0,0.3);
}
</style>

<div class="model-tabs">
<input type="radio" name="model-tab" id="model-tab-0" class="model-tab-radio" checked>
<label class="model-tab-btn" for="model-tab-0"><span style="font-size: 20px;">‚ö°</span> Ultra-Lightweight</label>

<input type="radio" name="model-tab" id="model-tab-1" class="model-tab-radio">
<label class="model-tab-btn" for="model-tab-1"><span style="font-size: 20px;">‚öñÔ∏è</span> Balanced</label>

<input type="radio" name="model-tab" id="model-tab-2" class="model-tab-radio">
<label class="model-tab-btn" for="model-tab-2"><span style="font-size: 20px;">üíª</span> Code</label>

<input type="radio" name="model-tab" id="model-tab-3" class="model-tab-radio">
<label class="model-tab-btn" for="model-tab-3"><span style="font-size: 20px;">üá©üá™</span> German</label>

<input type="radio" name="model-tab" id="model-tab-4" class="model-tab-radio">
<label class="model-tab-btn" for="model-tab-4"><span style="font-size: 20px;">‚öôÔ∏è</span> System/Tools</label>

<div class="model-tabs-container">

<!-- Ultra-Lightweight Content -->
<div class="model-tab-content model-content-0">
  <h4 style="color: #00e676; margin-top: 0; margin-bottom: 16px;">Ultra-Lightweight Models (1-2B)</h4>
  <p style="color: #b2dfdb; margin-bottom: 20px;">Perfect for quick tests, learning, and low-resource systems. Runs smoothly on any CPU with 4-6 GB RAM.</p>
  
  <div class="model-card" style="border-left-color: #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 6px; font-size: 1em;">tinyllama:1.1b ‚úÖ</div>
    <div style="font-size: 0.85em; color: #b2dfdb; line-height: 1.5;">
      <strong>Size:</strong> 600 MB | <strong>RAM:</strong> 4 GB<br>
      <strong>Use Case:</strong> Quick tests, learning basics, simple conversations<br>
      <strong>Speed:</strong> Very fast, CPU-friendly, instant responses<br>
      <strong>Status:</strong> Already installed and ready to use!
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/gemma:2b" target="_blank" style="color: #69f0ae; text-decoration: none;">gemma:2b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #b2dfdb; line-height: 1.5;">
      <strong>Size:</strong> 1.4 GB | <strong>RAM:</strong> 4-6 GB<br>
      <strong>Use Case:</strong> General purpose, chat, Q&A<br>
      <strong>Quality:</strong> Google's efficient model, great size/performance ratio<br>
      <strong>Best For:</strong> Upgrading from tinyllama while staying lightweight
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/qwen2.5:1.5b" target="_blank" style="color: #69f0ae; text-decoration: none;">qwen2.5:1.5b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #b2dfdb; line-height: 1.5;">
      <strong>Size:</strong> 930 MB | <strong>RAM:</strong> 4 GB<br>
      <strong>Use Case:</strong> Multilingual tasks, fast responses<br>
      <strong>Quality:</strong> Modern architecture, efficient and capable<br>
      <strong>Best For:</strong> Users needing multilingual support in tiny size
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/phi3.5:mini" target="_blank" style="color: #69f0ae; text-decoration: none;">phi3.5:mini üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #b2dfdb; line-height: 1.5;">
      <strong>Size:</strong> 2.2 GB | <strong>RAM:</strong> 6 GB<br>
      <strong>Use Case:</strong> Advanced reasoning, multilingual support<br>
      <strong>Best For:</strong> Microsoft's latest compact model, great performance
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00e676;">
    <div style="font-weight: 600; color: #00e676; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/smollm:1.7b" target="_blank" style="color: #69f0ae; text-decoration: none;">smollm:1.7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #b2dfdb; line-height: 1.5;">
      <strong>Size:</strong> 1 GB | <strong>RAM:</strong> 4 GB<br>
      <strong>Use Case:</strong> Efficient inference, mobile-friendly<br>
      <strong>Best For:</strong> Edge devices, lightweight applications
    </div>
  </div>
</div>

<!-- Balanced Content -->
<div class="model-tab-content model-content-1">
  <h4 style="color: #00b0ff; margin-top: 0; margin-bottom: 16px;">Balanced Models (3-7B)</h4>
  <p style="color: #81d4fa; margin-bottom: 20px;">Best quality-to-size ratio. Great for most tasks with 8-12 GB RAM. Industry standard performance.</p>
  
  <div class="model-card" style="border-left-color: #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/phi3:mini" target="_blank" style="color: #40c4ff; text-decoration: none;">phi3:mini üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #81d4fa; line-height: 1.5;">
      <strong>Size:</strong> 2.3 GB | <strong>RAM:</strong> 8 GB<br>
      <strong>Use Case:</strong> General chat, reasoning tasks, analysis<br>
      <strong>Quality:</strong> Microsoft model, excellent value for size<br>
      <strong>Best For:</strong> Most users upgrading from lightweight models
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/llama3.2:3b" target="_blank" style="color: #40c4ff; text-decoration: none;">llama3.2:3b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #81d4fa; line-height: 1.5;">
      <strong>Size:</strong> 2 GB | <strong>RAM:</strong> 8 GB<br>
      <strong>Use Case:</strong> Latest Meta model, versatile for all tasks<br>
      <strong>Quality:</strong> Top tier performance in 3B class<br>
      <strong>Best For:</strong> Users wanting cutting-edge capabilities
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/mistral:7b" target="_blank" style="color: #40c4ff; text-decoration: none;">mistral:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #81d4fa; line-height: 1.5;">
      <strong>Size:</strong> 4.1 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use Case:</strong> High-quality responses, complex tasks<br>
      <strong>Quality:</strong> Industry standard, proven in production<br>
      <strong>Best For:</strong> Professional use, detailed analysis
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/qwen2.5:7b" target="_blank" style="color: #40c4ff; text-decoration: none;">qwen2.5:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #81d4fa; line-height: 1.5;">
      <strong>Size:</strong> 4.7 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use Case:</strong> Advanced reasoning, multilingual support<br>
      <strong>Quality:</strong> State-of-the-art performance, highly capable<br>
      <strong>Best For:</strong> Complex reasoning and multi-language projects
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/llama3.1:8b" target="_blank" style="color: #40c4ff; text-decoration: none;">llama3.1:8b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #81d4fa; line-height: 1.5;">
      <strong>Size:</strong> 4.7 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use Case:</strong> General purpose, tool calling, function use<br>
      <strong>Best For:</strong> Meta's latest with extended context (128K tokens)
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #00b0ff;">
    <div style="font-weight: 600; color: #00b0ff; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/gemma2:9b" target="_blank" style="color: #40c4ff; text-decoration: none;">gemma2:9b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #81d4fa; line-height: 1.5;">
      <strong>Size:</strong> 5.4 GB | <strong>RAM:</strong> 14 GB<br>
      <strong>Use Case:</strong> Research, creative writing, detailed analysis<br>
      <strong>Best For:</strong> Google's powerful open model with high quality output
    </div>
  </div>
</div>

<!-- Code Specialist Content -->
<div class="model-tab-content model-content-2">
  <h4 style="color: #e040fb; margin-top: 0; margin-bottom: 16px;">Code Specialist Models</h4>
  <p style="color: #ce93d8; margin-bottom: 20px;">Optimized for programming tasks: code generation, debugging, completion, and refactoring.</p>
  
  <div class="model-card" style="border-left-color: #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/codegemma:2b" target="_blank" style="color: #ea80fc; text-decoration: none;">codegemma:2b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ce93d8; line-height: 1.5;">
      <strong>Size:</strong> 1.6 GB | <strong>RAM:</strong> 6 GB<br>
      <strong>Languages:</strong> Python, JavaScript, Java, C++, and more<br>
      <strong>Use Case:</strong> Lightweight code helper, quick snippets<br>
      <strong>Best For:</strong> Learning to code, simple automation scripts
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/codellama:7b" target="_blank" style="color: #ea80fc; text-decoration: none;">codellama:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ce93d8; line-height: 1.5;">
      <strong>Size:</strong> 3.8 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Languages:</strong> Python, Java, C++, JS, and more<br>
      <strong>Use Case:</strong> Code generation, debugging, documentation<br>
      <strong>Best For:</strong> Professional development, Meta's reliable coding model
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/qwen2.5-coder:7b" target="_blank" style="color: #ea80fc; text-decoration: none;">qwen2.5-coder:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ce93d8; line-height: 1.5;">
      <strong>Size:</strong> 4.7 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Languages:</strong> 92+ programming languages<br>
      <strong>Use Case:</strong> Advanced code tasks, architecture design<br>
      <strong>Best For:</strong> Top coding model in 7B class, complex projects
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/deepseek-coder:6.7b" target="_blank" style="color: #ea80fc; text-decoration: none;">deepseek-coder:6.7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ce93d8; line-height: 1.5;">
      <strong>Size:</strong> 3.8 GB | <strong>RAM:</strong> 10 GB<br>
      <strong>Languages:</strong> Specialized for popular languages<br>
      <strong>Use Case:</strong> Code completion, refactoring, optimization<br>
      <strong>Best For:</strong> Development workflows, IDE integration
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/starcoder2:3b" target="_blank" style="color: #ea80fc; text-decoration: none;">starcoder2:3b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ce93d8; line-height: 1.5;">
      <strong>Size:</strong> 1.7 GB | <strong>RAM:</strong> 6 GB<br>
      <strong>Languages:</strong> 600+ programming languages<br>
      <strong>Use Case:</strong> Code completion, faster lightweight coding<br>
      <strong>Best For:</strong> Lightweight code assistant, quick suggestions
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #e040fb;">
    <div style="font-weight: 600; color: #e040fb; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/granite-code:8b" target="_blank" style="color: #ea80fc; text-decoration: none;">granite-code:8b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ce93d8; line-height: 1.5;">
      <strong>Size:</strong> 4.6 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Languages:</strong> 116 programming languages<br>
      <strong>Use Case:</strong> Enterprise coding, bug fixing, code explanation<br>
      <strong>Best For:</strong> IBM's enterprise-grade coding model
    </div>
  </div>
</div>

<!-- German Language Content -->
<div class="model-tab-content model-content-3">
  <h4 style="color: #ff9100; margin-top: 0; margin-bottom: 16px;">German Language Optimized</h4>
  <p style="color: #ffcc80; margin-bottom: 20px;">Models with excellent German language support for professional and casual German text generation.</p>
  
  <div class="model-card" style="border-left-color: #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/llama3.2:3b" target="_blank" style="color: #ffab40; text-decoration: none;">llama3.2:3b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ffcc80; line-height: 1.5;">
      <strong>Size:</strong> 2 GB | <strong>RAM:</strong> 8 GB<br>
      <strong>Languages:</strong> Multilingual with strong German support<br>
      <strong>Use Case:</strong> German chat, Q&A, content creation<br>
      <strong>Best For:</strong> Best 3B model for German language tasks
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/mistral:7b" target="_blank" style="color: #ffab40; text-decoration: none;">mistral:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ffcc80; line-height: 1.5;">
      <strong>Size:</strong> 4.1 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Languages:</strong> Excellent German language capabilities<br>
      <strong>Use Case:</strong> Professional German text, business communication<br>
      <strong>Best For:</strong> High-quality German output, formal writing
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/aya:8b" target="_blank" style="color: #ffab40; text-decoration: none;">aya:8b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ffcc80; line-height: 1.5;">
      <strong>Size:</strong> 4.8 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Languages:</strong> 101 languages including German<br>
      <strong>Use Case:</strong> Multilingual projects, German + other languages<br>
      <strong>Best For:</strong> Specialized multilingual model with German focus
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #ff9100;">
    <div style="font-weight: 600; color: #ff9100; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/gemma2:9b" target="_blank" style="color: #ffab40; text-decoration: none;">gemma2:9b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #ffcc80; line-height: 1.5;">
      <strong>Size:</strong> 5.4 GB | <strong>RAM:</strong> 14 GB<br>
      <strong>Languages:</strong> Strong German language capabilities<br>
      <strong>Use Case:</strong> High-quality German content, formal writing<br>
      <strong>Best For:</strong> Professional German text with Google quality
    </div>
  </div>
</div>

<!-- System/Tools Content -->
<div class="model-tab-content model-content-4">
  <h4 style="color: #bdbdbd; margin-top: 0; margin-bottom: 16px;">System & Tools</h4>
  <p style="color: #e0e0e0; margin-bottom: 20px;">Specialized models for system administration, CLI workflows, scripting, and technical problem-solving.</p>
  
  <div class="model-card" style="border-left-color: #bdbdbd;">
    <div style="font-weight: 600; color: #bdbdbd; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/command-r:7b" target="_blank" style="color: #e0e0e0; text-decoration: none;">command-r:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #e0e0e0; line-height: 1.5;">
      <strong>Size:</strong> 4.1 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use Case:</strong> Command generation, CLI assistance, system tasks<br>
      <strong>Best For:</strong> Terminal workflows, Bash/PowerShell scripting
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #bdbdbd;">
    <div style="font-weight: 600; color: #bdbdbd; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/mistral-nemo:12b" target="_blank" style="color: #e0e0e0; text-decoration: none;">mistral-nemo:12b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #e0e0e0; line-height: 1.5;">
      <strong>Size:</strong> 7 GB | <strong>RAM:</strong> 16 GB<br>
      <strong>Use Case:</strong> Complex system analysis, advanced troubleshooting<br>
      <strong>Best For:</strong> DevOps, infrastructure management, logs analysis
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #bdbdbd;">
    <div style="font-weight: 600; color: #bdbdbd; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/nous-hermes2:11b" target="_blank" style="color: #e0e0e0; text-decoration: none;">nous-hermes2:11b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #e0e0e0; line-height: 1.5;">
      <strong>Size:</strong> 6.4 GB | <strong>RAM:</strong> 14 GB<br>
      <strong>Use Case:</strong> Function calling, structured outputs, tool use<br>
      <strong>Best For:</strong> API integration, automation scripts, agents
    </div>
  </div>
  
  <div class="model-card" style="border-left-color: #bdbdbd;">
    <div style="font-weight: 600; color: #bdbdbd; margin-bottom: 6px; font-size: 1em;">
      <a href="https://ollama.com/library/openchat:7b" target="_blank" style="color: #e0e0e0; text-decoration: none;">openchat:7b üîó</a>
    </div>
    <div style="font-size: 0.85em; color: #e0e0e0; line-height: 1.5;">
      <strong>Size:</strong> 4.1 GB | <strong>RAM:</strong> 12 GB<br>
      <strong>Use Case:</strong> Technical support, IT troubleshooting<br>
      <strong>Best For:</strong> Fast technical assistance, problem diagnosis
    </div>
  </div>
</div>

</div>
</div>

<div style="background: linear-gradient(135deg, #004d40 0%, #00695c 100%); padding: 14px; border-radius: 8px; border-left: 4px solid #4db6ac; margin-top: 16px;">
  <strong style="color: #b2dfdb;">üí° Quick Start:</strong> <span style="color: #e0f2f1;">Begin with <code style="background: rgba(0,0,0,0.4); padding: 2px 6px; border-radius: 3px;">tinyllama:1.1b</code> (included) or <code style="background: rgba(0,0,0,0.4); padding: 2px 6px; border-radius: 3px;">phi3:mini</code> for best balance. Download models in A1-Terminal's "Models" tab or via CLI: <code style="background: rgba(0,0,0,0.4); padding: 2px 6px; border-radius: 3px;">ollama pull model-name</code></span>
</div>


---


#####  Project Structure

```
A1-Terminal/
 scripts/
    install.bat          # Windows auto-installer
    install.sh           # Linux/macOS auto-installer
 start.bat               # Quick start (from root)
 a1_terminal_modular/
    main.py            # Entry point
    start.bat          # Windows start
    requirements.txt   # Dependencies
    a1_terminal_config.yaml  # Config
    sessions/          # Saved chats
    src/
        core/
           a1_terminal.py    # Main app
           ollama_manager.py # API client
        ui/
            ultimate_ui.py     # Modern UI
            chat_bubble.py     # Messages
            session_card.py    # Session list
            model_selector.py  # Model picker
            color_wheel.py     # Color picker
```

---



#####  Configuration

Auto-created `a1_terminal_config.yaml`:

```yaml
# Colors
user_bg_color: "#003300"
user_text_color: "#00FF00"
ai_bg_color: "#1E3A5F"
ai_text_color: "white"

# Fonts
user_font: "Courier New"
ai_font: "Consolas"

# UI
ui_window_width: 1400
ui_window_height: 900

# Options
show_system_messages: true
auto_scroll_chat: true
```


---

#####  Troubleshooting

**Ollama Not Running:**
```bash
ollama list      # Check status
ollama serve     # Start manually
```

**App Won't Start:**
```bash
pip install -r requirements.txt --upgrade
python --version  # Needs 3.8+
```

**Model Download Failed:**
- Check internet connection
- Try: ``ollama pull <model_name>``
- Check disk space
- Verify Ollama is running

---

#####  Documentation & Support

-  [Technical Documentation](https://github.com/Nr44suessauer/A1-Terminal/blob/main/DOCUMENTATION_EN.md){target="_blank"}
-  [GitHub Issues](https://github.com/Nr44suessauer/A1-Terminal/issues){target="_blank"}
-  [Discussions](https://github.com/Nr44suessauer/A1-Terminal/discussions){target="_blank"}

**Ready to start? Run the installation script!**

</div>

<div class="ollama-navbar-content ollama-content-4">

#### A1-Manual: Complete User Guide

##### üéØ Key Features Illustrated

- **[üñ•Ô∏è Console Initial Prompt](#console-initial-prompt)** 
- **[üîÑ Model Switching in Session](#model-switching)** 
- **[üí¨ Session Management](#session-management)**
- **[üé≠ Professional BIAS System](#bias-system)** 
- **[‚öôÔ∏è Configuration Screen](#configuration-screen)** 
- **[üìÅ Session Folder Structure (JSON)](#session-folder)** 
- **[üì• Download and Install](#download-install)**
- **[üé® Color Wheel & Session Settings](#color-wheel)** 

##### üì∏ Visual Walkthrough

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(500px, 1fr)); gap: 24px; margin: 24px 0;">
<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="console-initial-prompt" style="color: #60a5fa; margin-top: 0;">üñ•Ô∏è Console Initial Prompt</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/console_initial_prompt.png?raw=true" target="_blank">
        <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/console_initial_prompt.png?raw=true" alt="Console Initial Prompt" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
    <div style="color: #cbd5e1; margin: 0;">
        <p style="margin-bottom: 16px;">The console provides real-time process monitoring through log outputs, showing the ideal workflow.</p>
        <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üéØ Console Features:</h5>
        <ul style="margin: 8px 0; padding-left: 20px;">
            <li style="margin-bottom: 8px;"><strong>Process Overview:</strong> Real-time log outputs show system status and operations</li>
            <li style="margin-bottom: 8px;"><strong>Error Detection:</strong> Errors are displayed and deviate from the ideal process shown here</li>
            <li style="margin-bottom: 8px;"><strong>Model Status:</strong> Terminal displays whether the AI model is currently processing</li>
            <li><strong>System Monitoring:</strong> Complete visibility into application state and performance</li>
        </ul>
    </div>
</div>


<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="model-switching" style="color: #60a5fa; margin-top: 0;">üîÑ Model Switching in Session</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/modelchange_in_session.png?raw=true" target="_blank">
        <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/modelchange_in_session.png?raw=true" alt="Model Change in Session" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
    <div style="color: #cbd5e1; margin: 0;">
        <p style="margin-bottom: 16px;">Switch between different AI models mid-conversation to compare responses and capabilities.</p>
        <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üéØ Key Features:</h5>
        <ul style="margin: 8px 0; padding-left: 20px;">
            <li style="margin-bottom: 8px;"><strong>Multi-Session Support:</strong> Switch between multiple sessions with preserved content</li>
            <li style="margin-bottom: 8px;"><strong>Model Flexibility:</strong> Change models between or within sessions</li>
            <li style="margin-bottom: 8px;"><strong>Context Preservation:</strong> Automatic context retention when reopening sessions</li>
            <li style="margin-bottom: 8px;"><strong>Smart Management:</strong> Ollama handles conversation context automatically</li>
            <li><strong>Auto-Save:</strong> Sessions automatically saved after AI responses</li>
        </ul>
    </div>
</div>
<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="session-management" style="color: #60a5fa; margin-top: 0;">üí¨ Session Management</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/Session_astronaut.png?raw=true" target="_blank">
      <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/Session_astronaut.png?raw=true" alt="Session Example - Astronaut" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
    <div style="color: #cbd5e1; margin: 0;">
        <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-siSze: 1.1em;">üéØ Session Features:</h5>
        <ul style="margin: 8px 0; padding-left: 20px;">
            <li style="margin-bottom: 8px;"><strong>Visual Session Identification:</strong> The chat window frame is colored in the session color</li>
            <li style="margin-bottom: 8px;"><strong>Customizable Colors & Names:</strong> Color and name are set using the gear icon next to the session</li>
            <li style="margin-bottom: 8px;"><strong>BIAS Settings:</strong> The session BIAS setting is located in the bottom left; if no BIAS is set, this field is empty</li>
            <li style="margin-bottom: 8px;"><strong>JSON Storage:</strong> Sessions are stored in JSON format in the sessions folder, which opens when clicking the session-folder button</li>
            <li><strong>Session Preservation:</strong> All your conversations are preserved and can be restored anytime</li>
        </ul>
    </div>
</div>

<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="bias-system" style="color: #60a5fa; margin-top: 0;">üé≠ Professional BIAS System</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/session_Prof_BIAS.png?raw=true" target="_blank">
        <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/session_Prof_BIAS.png?raw=true" alt="Professional BIAS Configuration" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
    <div style="color: #cbd5e1; margin: 0;">
            <p style="margin-bottom: 16px;">Configure system prompts (BIAS) to define AI behavior and personality for each session.</p>
            <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üéØ BIAS System Features:</h5>
            <ul style="margin: 8px 0; padding-left: 20px;">
                    <li style="margin-bottom: 8px;"><strong>Professional Conversations:</strong> BIAS enables specialized technical discussions with AI - response quality depends on the model and hardware used</li>
                    <li style="margin-bottom: 8px;"><strong>Basic Queries:</strong> Fundamental questions can be easily asked and answered</li>
                    <li style="margin-bottom: 8px;"><strong>Critical Verification:</strong> Always remain skeptical and verify the received answers - AI responses should be fact-checked</li>
                    <li><strong>Session-Specific:</strong> Each session can have its own BIAS configuration for targeted conversations</li>
            </ul>
    </div>
</div>
<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="configuration-screen" style="color: #60a5fa; margin-top: 0;">‚öôÔ∏è Configuration Screen</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/screen_Config.png?raw=true" target="_blank">
        <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/screen_Config.png?raw=true" alt="Configuration Screen" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
    <div style="color: #cbd5e1; margin: 0;">
            <p style="margin-bottom: 16px;">Customize your A1-Terminal experience with colors, fonts, and UI preferences in the configuration screen.</p>
            <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üéØ Configuration Options:</h5>
            <ul style="margin: 8px 0; padding-left: 20px;">
                    <li style="margin-bottom: 8px;"><strong>Console Appearance:</strong> Adjust colors, shape, and size of the console interface</li>
                    <li style="margin-bottom: 8px;"><strong>Debug/System Outputs:</strong> Toggle debug and system message visibility on/off</li>
                    <li style="margin-bottom: 8px;"><strong>Auto-Scroll:</strong> Enable/disable automatic scrolling to the latest message</li>
                    <li><strong>Apply Changes:</strong> Clicking "Apply" triggers a restart script that closes and reopens the software automatically</li>
            </ul>
    </div>
</div>

<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="session-folder" style="color: #60a5fa; margin-top: 0;">üìÅ Session Folder Structure (JSON)</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/folder_Session_Json.png?raw=true" target="_blank">
        <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/folder_Session_Json.png?raw=true" alt="Session JSON Storage" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
            <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üîí Privacy & Data Protection:</h5>
            <ul style="margin: 8px 0; padding-left: 20px;">
                    <li style="margin-bottom: 8px;"><strong>Local Session Logs:</strong> Complete conversation histories for retrieval, sharing, and analysis</li>
                    <li style="margin-bottom: 8px;"><strong>Valuable Personal Data:</strong> These datasets reveal thinking patterns and personality traits - highly valuable to platforms like OpenAI</li>
                    <li style="margin-bottom: 8px;"><strong>Full Local Control:</strong> Your conversations remain on your machine, never sent to external servers</li>
                    <li><strong>Data Sovereignty:</strong> You decide what happens with your data - share, analyze, or keep private</li>
            </ul>
    </div>
<div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
    <h4 id="download-install" style="color: #60a5fa; margin-top: 0;">üì• Download and Install</h4>
    <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/download_and_install.png?raw=true" target="_blank">
        <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/download_and_install.png?raw=true" alt="Download and Install" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
    </a>
    <div style="color: #cbd5e1; margin: 0;">
        <p style="margin-bottom: 16px;">The model download interface allows you to browse and install AI models directly from the application.</p>
        <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üéØ Download Features:</h5>
        <ul style="margin: 8px 0; padding-left: 20px;">
            <li style="margin-bottom: 8px;"><strong>Model Browser:</strong> Browse available models categorized by size and performance</li>
            <li style="margin-bottom: 8px;"><strong>Progress Tracking:</strong> Real-time download progress with speed indicators</li>
            <li style="margin-bottom: 8px;"><strong>Space Requirements:</strong> Clear disk space and RAM requirements for each model</li>
            <li style="margin-bottom: 8px;"><strong>Model Folder Access:</strong> Direct access to the local model storage folder for file management</li>
            <li><strong>One-Click Install:</strong> Simple installation process directly from the interface</li>
        </ul>
    </div>
</div>
    <div style="background: #1e293b; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.2);">
        <h4 id="color-wheel" style="color: #60a5fa; margin-top: 0;">üé® Color Wheel & Session Settings</h4>
        <a href="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/colorwheel.png?raw=true" target="_blank">
            <img src="https://github.com/Nr44suessauer/nr44suessauer.github.io/blob/main/nuxt-app/assets/pictures/A1-Terminal/colorwheel.png?raw=true" alt="Color Wheel Interface" style="width: 100%; border-radius: 8px; margin-bottom: 12px; cursor: pointer; transition: transform 0.3s;">
        </a>
        <div style="color: #cbd5e1; margin: 0;">
            <p style="margin-bottom: 16px;">Access this customization window by clicking the gear icon next to any session in the session list.</p>
            <h5 style="color: #60a5fa; margin: 16px 0 8px 0; font-size: 1.1em;">üéØ Session Customization Features:</h5>
            <ul style="margin: 8px 0; padding-left: 20px;">
                <li style="margin-bottom: 8px;"><strong>Session Name:</strong> Set or change the session name in the text field at the top</li>
                <li style="margin-bottom: 8px;"><strong>Visual Color Picker:</strong> Intuitive color wheel interface for precise color selection</li>
                <li style="margin-bottom: 8px;"><strong>Real-Time Preview:</strong> See color changes instantly as you adjust the wheel</li>
                <li style="margin-bottom: 8px;"><strong>Session Theming:</strong> Customize individual session colors for easy identification</li>
                <li><strong>Persistent Settings:</strong> Both color and name choices are saved and restored when reopening sessions</li>
            </ul>
        </div>
    </div>
</div>
</div>


<style>
/* Main Tabs (How AI Works, Preparation, etc.) */
.ollama-navbar-tabs {
  width: 100%;
}
.ollama-tab-radio {
  display: none;
}
.ollama-navbar-btn {
  background: #007bff;
  color: white;
  border: none;
  border-radius: 6px 6px 0 0;
  padding: 12px 32px;
  font-size: 1em;
  font-weight: bold;
  cursor: pointer;
  transition: background 0.2s;
  outline: none;
}
.ollama-navbar-btn.active,
.ollama-navbar-btn:hover {
  background: #0056b3;
}
.ollama-navbar-content {
  display: none;
}
#ollama-tab-0:checked ~ .ollama-navbar .ollama-navbar-btn[for="ollama-tab-0"],
#ollama-tab-1:checked ~ .ollama-navbar .ollama-navbar-btn[for="ollama-tab-1"],
#ollama-tab-2:checked ~ .ollama-navbar .ollama-navbar-btn[for="ollama-tab-2"],
#ollama-tab-3:checked ~ .ollama-navbar .ollama-navbar-btn[for="ollama-tab-3"],
#ollama-tab-4:checked ~ .ollama-navbar .ollama-navbar-btn[for="ollama-tab-4"] {
  background: #0056b3;
}
#ollama-tab-0:checked ~ .ollama-content-0,
#ollama-tab-1:checked ~ .ollama-content-1,
#ollama-tab-2:checked ~ .ollama-content-2,
#ollama-tab-3:checked ~ .ollama-content-3,
#ollama-tab-4:checked ~ .ollama-content-4 {
  display: block;
}

/* Installation Tabs (Windows/Linux) */
.install-tabs {
  margin: 24px 0;
}

.install-tabs .tab-input {
  display: none;
}

.install-tabs .tab-buttons {
  display: flex;
  gap: 8px;
  margin-bottom: 0;
  border-bottom: none;
  background: transparent !important;
  position: relative;
  z-index: 10;
}

/* Base styling for all tabs */
.install-tabs .tab-button {
  color: white !important;
  border: none !important;
  border-radius: 8px 8px 0 0 !important;
  padding: 12px 32px !important;
  font-size: 1em !important;
  font-weight: 600 !important;
  cursor: pointer !important;
  transition: all 0.3s ease !important;
  border-bottom: 3px solid transparent !important;
  display: inline-block !important;
  position: relative !important;
  z-index: 10 !important;
  text-decoration: none !important;
}

/* Windows Tab Colors - Very specific */
.install-tabs .tab-buttons label.tab-button[for="auto-windows"],
.install-tabs .tab-buttons label.tab-button[for="manual-windows"] {
  background-color: #0078d4 !important;
  background-image: none !important;
  box-shadow: 0 2px 6px rgba(0,120,212,0.4) !important;
}

.install-tabs .tab-buttons label.tab-button[for="auto-windows"]:hover,
.install-tabs .tab-buttons label.tab-button[for="manual-windows"]:hover {
  background-color: #005a9e !important;
  background-image: none !important;
  transform: translateY(-2px) !important;
  box-shadow: 0 4px 8px rgba(0,120,212,0.5) !important;
}

/* Linux/macOS Tab Colors - Very specific */
.install-tabs .tab-buttons label.tab-button[for="auto-linux"],
.install-tabs .tab-buttons label.tab-button[for="manual-linux"] {
  background-color: #f57c00 !important;
  background-image: none !important;
  box-shadow: 0 2px 6px rgba(255,145,0,0.4) !important;
}

.install-tabs .tab-buttons label.tab-button[for="auto-linux"]:hover,
.install-tabs .tab-buttons label.tab-button[for="manual-linux"]:hover {
  background-color: #e65100 !important;
  background-image: none !important;
  transform: translateY(-2px) !important;
  box-shadow: 0 4px 8px rgba(255,145,0,0.5) !important;
}

.install-tabs .tab-content {
  display: none;
  background: rgba(0,0,0,0.1);
  border-radius: 0 8px 8px 8px;
  padding: 24px;
  border: 2px solid currentColor;
  animation: fadeIn 0.3s ease;
  color: inherit;
  opacity: 0.85;
}

.install-tabs .tab-content strong {
  color: inherit;
  font-weight: 700;
}

.install-tabs .tab-content code {
  background: rgba(0, 0, 0, 0.3);
  padding: 2px 6px;
  border-radius: 4px;
  color: inherit;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(-10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

/* Automatic Installation Tabs */
#auto-windows:checked ~ .tab-buttons label[for="auto-windows"],
#manual-windows:checked ~ .tab-buttons label[for="manual-windows"] {
  background: #0078d4 !important;
  border-bottom-color: #0078d4;
  box-shadow: 0 4px 10px rgba(0,120,212,0.6);
  transform: scale(1.02);
}

#auto-linux:checked ~ .tab-buttons label[for="auto-linux"],
#manual-linux:checked ~ .tab-buttons label[for="manual-linux"] {
  background: #f57c00 !important;
  border-bottom-color: #f57c00;
  box-shadow: 0 4px 10px rgba(255,145,0,0.6);
  transform: scale(1.02);
}

/* Tab Content Border Colors */
#auto-windows:checked ~ #auto-windows-content {
  border-color: #0078d4;
  background: rgba(0, 120, 212, 0.1);
}

#auto-linux:checked ~ #auto-linux-content {
  border-color: #f57c00;
  background: rgba(245, 124, 0, 0.1);
}

#manual-windows:checked ~ #manual-windows-content {
  border-color: #0078d4;
  background: rgba(0, 120, 212, 0.1);
}

#manual-linux:checked ~ #manual-linux-content {
  border-color: #f57c00;
  background: rgba(245, 124, 0, 0.1);
}

#auto-windows:checked ~ #auto-windows-content,
#auto-linux:checked ~ #auto-linux-content,
#manual-windows:checked ~ #manual-windows-content,
#manual-linux:checked ~ #manual-linux-content {
  display: block;
}
</style>
